{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary library\n",
    "import pandas as pd\n",
    "import re \n",
    "import en_core_web_sm\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from lyricParser import tokenizeLyrics\n",
    "from pathlib import Path\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a filepath for the file\n",
    "filePath = Path('resources', 'drake_kanye.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>tracklist_position</th>\n",
       "      <th>song</th>\n",
       "      <th>album</th>\n",
       "      <th>release_date</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drake</td>\n",
       "      <td>1</td>\n",
       "      <td>Champagne Poetry</td>\n",
       "      <td>Certified Lover Boy</td>\n",
       "      <td>2021-09-03</td>\n",
       "      <td>[Part I]\\n\\n[Intro]\\nI love you, I love you, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drake</td>\n",
       "      <td>2</td>\n",
       "      <td>Papi's Home</td>\n",
       "      <td>Certified Lover Boy</td>\n",
       "      <td>2021-09-03</td>\n",
       "      <td>[Intro: Drake &amp; Montell Jordan]\\nI know that I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist  tracklist_position              song                album  \\\n",
       "0  Drake                   1  Champagne Poetry  Certified Lover Boy   \n",
       "1  Drake                   2       Papi's Home  Certified Lover Boy   \n",
       "\n",
       "  release_date                                             lyrics  \n",
       "0   2021-09-03  [Part I]\\n\\n[Intro]\\nI love you, I love you, I...  \n",
       "1   2021-09-03  [Intro: Drake & Montell Jordan]\\nI know that I...  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "trackXlsx = pd.read_excel(filePath)\n",
    "trackXlsx = pd.DataFrame(trackXlsx)\n",
    "trackXlsx.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the language model\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create csv file\n",
    "csv_file = open('lyrics_tokenized_v1.csv', 'w', encoding=\"utf-8\", newline=\"\")\n",
    "\n",
    "# create columns \n",
    "csv_writer = csv.writer(csv_file, delimiter=\";\")\n",
    "csv_writer.writerow(['id','artist','track_position','song','album','realse_date','lyrics'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for index, row in trackXlsx.iterrows():\n",
    "    artist          = row[\"artist\"]\n",
    "    position        = row[\"tracklist_position\"]\n",
    "    song_name       = row[\"song\"]\n",
    "    album           = row[\"album\"]\n",
    "    release_date    = row[\"release_date\"]\n",
    "    lyrics          = row[\"lyrics\"]\n",
    "\n",
    "    lyrics_tokenized = tokenizeLyrics(lyrics, nlp)\n",
    "\n",
    "    for word in lyrics_tokenized:\n",
    "         csv_writer.writerow([counter,artist,position,song_name,album,release_date,word])\n",
    "         counter += 1\n",
    "\n",
    "csv_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrack(id, artist, track_position, song, release_date, lyrics):\n",
    "    value = {\n",
    "        \"id\":id, \n",
    "        \"artist\":artist,\n",
    "        \"track_psition\":track_position,\n",
    "        \"song\":song,\n",
    "        \"release_date\":release_date,\n",
    "        \"lyrics\":lyrics\n",
    "        }\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createJson(filename, trackList):\n",
    "\n",
    "    data = {'data': trackList}\n",
    "\n",
    "    with open(f'{filename}.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"[Intro]\" etc BEFORE tokenization in order to prevent the removal \n",
    "# if words like \"verse, intro\" from the actual lyrics\n",
    "\n",
    "text = re.sub(\"[\\[].*?[\\]]\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the language model\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenizeText(text):\n",
    "\n",
    "#     # load the text into spacy\n",
    "#     document = nlp(text)\n",
    "\n",
    "#     # tokenize\n",
    "#     tokens = [word.text for word in document]\n",
    "\n",
    "#     # lowercase EVERYTHING\n",
    "#     tokens_lower = [token.lower() for token in tokens]\n",
    "\n",
    "#     # Import a module that helps with string processing\n",
    "#     import string\n",
    "\n",
    "#     # Make a table that translates all punctuation to an empty value (`None`)\n",
    "#     table = str.maketrans('', '', string.punctuation)\n",
    "#     tokens_nopunct = [token.translate(table) for token in tokens_lower]\n",
    "\n",
    "#     # remove \"None\" from the tokens\n",
    "#     tokens_notempty = [token for token in tokens_nopunct if token != '']\n",
    "\n",
    "#     # remove single characters \n",
    "#     tokens_noSingleLetters = [token for token in tokens_nopunct if len(token) >1 ]\n",
    "\n",
    "#     # remove escape squences & numbers\n",
    "#     tokens = [token for token in tokens_noSingleLetters if token.isalpha()]\n",
    "\n",
    "#     # import stopwords\n",
    "#     stopwords = [stop for stop in STOP_WORDS]\n",
    "\n",
    "#     # remove stopwords\n",
    "#     tokens_nostops = [token for token in tokens if token not in stopwords]\n",
    "\n",
    "#     return tokens_nostops"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2729df46c5106bf62ff4613815d394766823acc017e391f5114442a92a148c0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
